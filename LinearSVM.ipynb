{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LinearSVM.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "8G3amYrzBiq3"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM6/istTNLvMuTqFE/lIlQR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DrManishSharma/SVM/blob/main/LinearSVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8G3amYrzBiq3"
      },
      "source": [
        "# <center> <font color=violet><b> Linear SVM </b></span> </center>\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vp2TqXDCdwB"
      },
      "source": [
        "# 1. Background of SVM\n",
        "SVM is <ul>\n",
        "<li>Supervised Machine Learning Algorithm</li>\n",
        "<li>Used for <b>Classification</b> and Regression</li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTM8nXGsGtZI"
      },
      "source": [
        "## Optimization of SVM\n",
        "Optimization depends upon <b>dot product of the pairs of vectors</b>\n",
        "\n",
        "<ul>\n",
        "<li> Derrivation </li>\n",
        "    \n",
        "<figure>\n",
        "<center>\n",
        "<img src='https://drive.google.com/uc?export=view&id=1Q_7qJfIZkVEBiW_0UAF8DnFUEUIJrnA2' width=50% />\n",
        "<figcaption>Figure 1</figcaption></center>\n",
        "</figure>\n",
        "\n",
        "Assume a binary classification problem as shown in figure above, inorder to separate the two classes in 2D a decision boundary needs to be decided. If the boundary separating the classes is linear the classes are said to be linearly separable.\n",
        "\n",
        "Multiple lines can act as the decision boundary which separates the two classes (look at the figure below). \n",
        "\n",
        "<figure>\n",
        "<center>\n",
        "<img src='https://drive.google.com/uc?export=view&id=1SnMqZIGWdyGfcMIqwkGqMrklp9hwdYN5' width=50% />\n",
        "<figcaption>Figure 2</figcaption></center>\n",
        "</figure>\n",
        "\n",
        "How to decide whether blue, yellow, green or someother line is the best decision boundary?\n",
        "Inorder to define the best decision boundary we use the principle of maximum margin. The boundary which is at the maximum distance from the nearest members of both the class is selected as the best boundary. In the figure below the hashed lines are the lines passing through the nearest points of the + and - class. Distance from the yellow line to the hashed line is define as the margin. Given that among all the possible lines separating the two classes the yellow line has the highest marging then the yellow line is the best decsion boundary. The points of both the classes through which the hashed yellow line passes is/are known as support vector(s). \n",
        "\n",
        "<figure>\n",
        "<center>\n",
        "<img src='https://drive.google.com/uc?export=view&id=1h9fiCmTw8UPJokzBoG23y2_RpQcDOs9R' width=50% />\n",
        "<figcaption>Figure 3</figcaption></center>\n",
        "</figure>\n",
        "\n",
        "In order to maximize the the margins or distance between two hashed lines we need to create an expression and take derrivative of it to find the optimum (extremum) value. Assume a vector $w \\ $ which is normal to the decision boundary and an unknown vector $u \\ $. Inorder to decide weather the unknown vector $u \\ $ lies in the side of - ive class or + ive class we meassure the length of projection of $u \\ $ on $w \\ $ if it is greater than a certain length it is in +ive class or else it belongs to -ive class (or lies on the margin).\n",
        "\n",
        "$$ u \\cdot w + b \\  \\geq 0 \\ for \\ +ive \\ class $$ \n",
        "\n",
        "Inorder to differentiate between + and - class we assume that if the unknown vector is a vector from + class ($x_{+} \\ $) it should give a value greater than one or if it is a vector from - class ($x_{-} \\ $) it should give a value less than -1. +1 and -1 value is decided to bring in the clear separation between both the classes. So mathematically the condition is:\n",
        "  \n",
        "\n",
        "  $$ x_{+} \\cdot w + b \\  \\geq 1  $$\n",
        "  $$ x_{-} \\cdot w + b \\  \\leq -1  $$\n",
        "\n",
        "For mathematical convenience let's introduce a variable $ y_{i} $ such that $ y_{i} $ = 1 for + samples and $ y_{i} $ = -1 for - samples. Multiplying $ y_{i} $ with the equations above we get:\n",
        "\n",
        " $$ y_{i}(x_{i} \\cdot w + b )\\ - 1 \\geq 0  $$\n",
        "\n",
        "The support vector from + class ($ x_{+sv} $) and - class ($ x_{-sv} $) lies on the margin itself. So the projection of the vector ($ x_{+sv} - x_{-sv} $) $\\cdot w/|w|$ on normal $ w $ is the distance between the margins. This distance should be maximized with the constraints given above. \n",
        "\n",
        "<ul>\n",
        "<li> maximize: $$  (x_{+sv} - x_{-sv}) \\cdot  \\frac{w}{|w|}  $$ </li>\n",
        "from equation above: \n",
        "<ul>\n",
        "<li>$$  x_{+sv} \\cdot w = 1 - b  $$</li>\n",
        "<li>$$  x_{-sv} \\cdot w = -1 - b  $$</li>\n",
        "</ul>\n",
        "thus the maximum condition becomes: 2/|w| or it can be changed to:\n",
        "<li><b>minimize:</b> $$  \\frac{1}{2} |w|^{2} $$</li>\n",
        "<li> <b>constraint: $$ y_{i}(x_{i} \\cdot w + b )\\ - 1 = 0 $$</b> </li>\n",
        "</ul>\n",
        "To find an extremum along with constraints we can use Langrange multiplier,\n",
        "$$ L = \\frac{1}{2} |w|^{2} - \\sum \\alpha_{i}[ y_{i}(x_{i} \\cdot w + b )\\ - 1 ] $$</b>\n",
        "<li> The minimum of Lagrangian is:\n",
        "$$  L_{min} = \\sum \\alpha_{i} - \\frac{1}{2} \\sum_{i} \\sum_{j} \\alpha_{i} \\alpha_{j}y_{i}y_{j}  x_{i} \\cdot x_{j} $$</li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDt1s0lzz2ms"
      },
      "source": [
        "## If classes are linearly non-separable\n",
        "In such cases adding extra features and transforming the vectors to higher dimension might help in separating the vectors by a plane (hyper plane). For example assume two classes c1(blue) and c2(orange) shown in the figure below. **There seem to be no linear decision boundary for the two classes. What if a new dimension is added to the data x2 = (x1)^2**. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "cellView": "form",
        "id": "5_ijEP-O0lnE",
        "outputId": "8c7fcb5b-dab0-4c12-f17d-7fdc46ecd433"
      },
      "source": [
        "#@title Non Linearly Separable Data\n",
        "import matplotlib.pyplot as plt\n",
        "c1 = [-4, -3,-2,2,3,4]\n",
        "c2 = [-1,-0.5,-0.25,0.25,0.5,1]\n",
        "y = [0, 0, 0, 0, 0, 0]\n",
        "plt.scatter(x1,y)\n",
        "plt.scatter(x2,y)\n",
        "plt.xlabel('x1', fontsize=20)\n",
        "plt.ylabel('x2', fontsize=20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'x2')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "cellView": "form",
        "id": "HFIt8lg03Dds",
        "outputId": "79bad0f7-8b8d-4bf6-eec7-631f348ba04d"
      },
      "source": [
        "#@title Transforming linear data to higher dimension to make it linearly separable\n",
        "y1 = [16,9,4,4,9,16]\n",
        "y2 = [1,0.25,0.0625,0.0625,0.25,1]\n",
        "y3 = [2,2,2,2,2,2]\n",
        "plt.scatter(c1,y1)\n",
        "plt.scatter(c2,y2)\n",
        "plt.xlabel('x1', fontsize=20)\n",
        "plt.ylabel('x2', fontsize=20)\n",
        "plt.plot(c1,y3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fc8daf577d0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEPCAYAAACp/QjLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAUfElEQVR4nO3de5Scd33f8fcnshxkbgrxAvGllZOCchzHWHSTmkKKwSRyEoNM0riYwoHg1imHWxMiH4RPcGnCKYlIIBxyU2zXKfZx4oIQl4TIDnFw0ziGleW7rJBDAUsy0XJcOW5RsWx/+8fMwmqflbSjnZ3nkeb9Okdnd37z7DMfj2fmM889VYUkSbN9V9sBJEndYzlIkhosB0lSg+UgSWqwHCRJDSe0HWBYTj755Fq1alXbMSTpmLJt27ZvVNXE3PHjphxWrVrF1NRU2zEk6ZiS5KvzjbtaSZLUYDlIkhosB0lSg+UgSWqwHCRJDa3urZTkGuBCYG9VnTVr/G3AW4AngD+tqsuX4vG3bN/Nxq072bNvP6esXMH6tau5aM2pS/FQkjR0S/kZ1vaurNcCHwH+28xAkpcB64AXVNW3kjx7KR54y/bdbNh8D/sPPAHA7n372bD5HgALQlLnLfVnWKurlarqVuDhOcNvBt5fVd/qT7N3KR5749ad335SZ+w/8AQbt+5cioeTpKFa6s+wLm5zeD7wY0luT/L5JD9yqAmTXJZkKsnU9PT0QA+yZ9/+gcYlqUuW+jOsi+VwAvAs4FxgPXBjksw3YVVtqqrJqpqcmGgc/X1Yp6xcMdC4JHXJUn+GdbEcdgGbq+cLwJPAycN+kPVrV7Ni+bKDxlYsX8b6tauH/VCSNHRL/RnW9gbp+WwBXgbckuT5wInAN4b9IDMbbNxbSdKxaKk/w9LmNaST3ACcR2/J4B+AK4GPAtcA5wCPAb9cVX95pHlNTk6WJ96TpMEk2VZVk3PHW11yqKpLDnHX60YaRJJ0kC5uc5AktcxykCQ1WA6SpAbLQZLUYDlIkhosB0lSg+UgSWqwHCRJDZaDJKnBcpAkNVgOkqQGy0GS1GA5SJIaLAdJUoPlIElqsBwkSQ2tlkOSa5LsTXLvPPe9M0klGfr1oyVJh9f2ksO1wAVzB5OcDvwE8LVRB5IktVwOVXUr8PA8d30QuBxo7wLXkjTG2l5yaEiyDthdVXctYNrLkkwlmZqenh5BOkkaD50qhyQnAe8G3rOQ6atqU1VNVtXkxMTE0oaTpDHSqXIAfgA4A7gryVeA04A7kjy31VSSNGZOaDvAbFV1D/Dsmdv9gpisqm+0FkqSxlDbu7LeANwGrE6yK8mlbeaRJPW0uuRQVZcc4f5VI4oiSZqla9scJEkdYDlIkhosB0lSg+UgSWqwHCRJDZaDJKnBcpAkNVgOkqQGy0GS1GA5SJIaLAdJUoPlIElqsBwkSQ2WgySpwXKQJDVYDpKkhravBHdNkr1J7p01tjHJA0nuTvKJJCvbzChJ46jtJYdrgQvmjN0MnFVVZwN/B2wYdShJGnetlkNV3Qo8PGfspqp6vH/zb4HTRh5MksZc20sOR/Im4LOHujPJZUmmkkxNT0+PMJYkHd86Ww5JrgAeB64/1DRVtamqJqtqcmJiYnThJOk4d0LbAeaT5I3AhcD5VVUtx5GksdO5ckhyAXA58NKq+mbbeSRpHLW9K+sNwG3A6iS7klwKfAR4OnBzkjuT/H6bGSVpHLW65FBVl8wzfPXIg0iSDtLZDdKSpPZYDpKkBstBktRgOUiSGiwHSVKD5SBJarAcJEkNloMkqcFykCQ1WA6SpAbLQZLUYDlIkhosB0lSg+UgSWqwHCRJDZaDJKmh7SvBXZNkb5J7Z409K8nNSb7U//k9bWaUpHHU9pLDtcAFc8beBXyuqp4HfK5/W5I0Qq2WQ1XdCjw8Z3gd8Ef93/8IuGikoSRJrS85zOc5VfVQ//evA8851IRJLksylWRqenp6NOkkaQx0sRy+raoKqMPcv6mqJqtqcmJiYoTJJOn41sVy+Ick3wfQ/7m35TySNHa6WA6fAt7Q//0NwCdbzCJJY6ntXVlvAG4DVifZleRS4P3Ajyf5EvCK/m1J0gid0OaDV9Ulh7jr/JEGkSQdpIurlSRJLbMcJEkNloMkqaHVbQ6a35btu9m4dSd79u3nlJUrWL92NRetObXtWNJYGtf3o+XQMVu272bD5nvYf+AJAHbv28+GzfcAjMULUuqScX4/ulqpYzZu3fntF+KM/QeeYOPWnS0lksbXOL8fLYeO2bNv/0DjkpbOOL8fLYeOOWXlioHGJS2dcX4/Wg4ds37talYsX3bQ2Irly1i/dnVLiaTxNc7vRzdId8zMRq5x3DtC6ppxfj+md1bsBUyYrAHOAx4HbqqqebfIJFkHrKuqNw0r5EJMTk7W1NTUKB9Sko55SbZV1eTc8QWtVkryAWAK+ADwIeC+JB9Osnyeyc/hO2dVlSQdg45YDkleDfwS8ChwFfB7wDTwFuCmJCctaUJJ0sgtZMnhzcD/A/5FVf1CVb0VeD7wceClwGeSPGUJM0qSRmwh5fBCYPPsbQxV9WhVXUxvFdN5wKeTfPfSRJQkjdpCyuFpwFfnu6OqfonedojzgS1JThxWsCS/mOS+JPcmucGlE0kanYWUw0PAcw91Z1VdDvw2sJbeqqZFF0SSU4G3A5NVdRawDHjNYucrSVqYhRznsIPetoVDqqpf7C81vBl42TCC0cu2IskB4CRgz5DmK0k6goUsOXwW+P4kP3a4iarqLcDV9D7IF6WqdtNbXfU1eksuj1TVTXOnS3JZkqkkU9PT04t9WElS30KWHD4OnAJ875EmrKp/n2QXsGoxoZJ8D7AOOAPYB/z3JK+rquvmPN4mYBP0DoJbzGNKkr7jiOVQVXuADQudYVW9N8liT8vxCuB/VdU0QJLNwL8ErjvsX0mShmKgE+8l+cMj7TWUZBXw14vIBL3VSecmOSlJ6O0NtWOR85QkLdCgZ2W9FPhCkh+c784kPwtsB35kMaGq6nbgY8AdwD39nJsWM09J0sINWg7vA84EppL8/MxgkhOT/C5wI/AE8OrFBquqK6vqB6vqrKp6fVV9a7HzlCQtzEDlUFW/Qu94hkeBq5J8NMkk8AXgPwB/A5xTVZ8aelJJ0sgMfLGfqvocvTOv/gXwWuB24IeAXwNeWlW7hppQkjRyR7tX0aP0zsya/u1HgM9X1ZNDSSVJatXASw5JXkBvQ/ElwE30ViedCGxN8r4kXnpUko5xg+7K+lbgNuD7gXdX1QX9A9H+OXA38C7gfyQ5fehJJUkjM+i3/A8De+ltW/j1mcGq+hJwLvC7wIuAO4eWUJI0coOWwyeBNVV129w7quqxqnob8LNDSSZJas1AG6Sr6ojHL1TVJ5JMHX0kSVLblmTjcVU9uBTzlSSNhnsWSZIaLAdJUoPlIElqsBwkSQ2WgySpwXKQJDVYDpKkhs6WQ5KVST6W5IEkO5K8qO1MkjQujvaU3aPw28CfV9W/TnIicFLbgSRpXHSyHJI8E/hXwBuhd94m4LE2M0nSOOnqaqUz6F1M6L8m2Z7kqiRPnTtRksuSTCWZmp6eHn1KSTpOdbUcTgBeCPxeVa0B/i+9a0UcpKo2VdVkVU1OTEyMOqMkHbe6Wg67gF1VdXv/9sfolYUkaQQ6WQ5V9XXgwSSr+0PnA/e3GEmSxkonN0j3vQ24vr+n0peBn285jySNjc6WQ1XdCUy2nUOSxlEnVytJktplOUiSGiwHSVKD5SBJarAcJEkNloMkqcFykCQ1WA6SpAbLQZLUYDlIkhosB0lSg+UgSWqwHCRJDZaDJKnBcpAkNVgOkqSGzl7sByDJMmAK2F1VF7adZ9xt2b6bjVt3smfffk5ZuYL1a1dz0ZpT246l44Svr27pdDkA7wB2AM9oO8i427J9Nxs238P+A08AsHvffjZsvgfAN7AWzddX93R2tVKS04CfBq5qO4tg49ad337jzth/4Ak2bt3ZUiIdT3x9dU9nywH4EHA58OShJkhyWZKpJFPT09OjSzaG9uzbP9C4NAhfX93TyXJIciGwt6q2HW66qtpUVZNVNTkxMTGidOPplJUrBhqXBuHrq3s6WQ7Ai4FXJfkK8MfAy5Nc126k8bZ+7WpWLF920NiK5ctYv3Z1S4l0PPH11T2d3CBdVRuADQBJzgN+uape12qoMTezUdC9SbQUfH11TyfLQd100ZpTfbNqyfj66pbOl0NV/RXwVy3HkKSx0tVtDpKkFlkOkqQGy0GS1GA5SJIaLAdJUoPlIElqsBwkSQ2WgySpwXKQJDVYDpKkBstBktRgOUiSGiwHSVKD5SBJarAcJEkNloMkqaGT5ZDk9CS3JLk/yX1J3tF2JkkaJ129EtzjwDur6o4kTwe2Jbm5qu5vO5gkjYNOlkNVPQQ81P/90SQ7gFOBoZfDez99H/fv+cdhz1aSRubMU57Bla/8oaHOs5OrlWZLsgpYA9w+z32XJZlKMjU9PT3qaJJ03EpVtZ3hkJI8Dfg88L6q2ny4aScnJ2tqamo0wSTpOJFkW1VNzh3v7JJDkuXAx4Hrj1QMkqTh6mQ5JAlwNbCjqn6r7TySNG46WQ7Ai4HXAy9Pcmf/30+1HUqSxkVX91b6ayBt55CkcdXVJQdJUossB0lSg+UgSWqwHHTsu/tG+OBZ8J9W9n7efWPbibrN50sL0MkN0tKC3X0jfPrtcGB/7/YjD/ZuA5x9cXu5usrnSwvkkoOObZ/7z9/5oJtxYH9vXE0+X1ogy0HHtkd2DTY+7ny+tECWg45tzzxtsPFx5/OlBbIcdGw7/z2wfMXBY8tX9MbV5POlBbIcdGw7+2J45YfhmacD6f185YfduHooPl9aoE6fsnsQnrJbkgZ3zJ2yW5LUHstBktRgOUizdfXo4a7m0nHLI6SlGV09eriruXRcc8lBmjHI0cPD/CZ/pHl5VLNa0NlySHJBkp1J/j7Ju9rOozGw0KOHZ77JP/IgUN/5Jn80BbGQeXlUs1rQyXJIsgz4HeAngTOBS5Kc2W4qHfcWevTwML/JL2ReHtWsFnSyHIAfBf6+qr5cVY8BfwysazmTjncLPXp4mN/kFzIvj2pWC7paDqcCD866vas/dpAklyWZSjI1PT09snA6Ti306OFhfpNfyLw8qlktOKb3VqqqTcAm6B0h3XIcHQ/OvvjIH7rnv+fgvYfg6L/JL3ReC8klDVFXlxx2A6fPun1af0xq3zC/ybtUoI7q5LmVkpwA/B1wPr1S+CLw2qq671B/47mVJGlwhzq3UidXK1XV40neCmwFlgHXHK4YJEnD1clyAKiqPwP+rO0ckjSOurrNQZLUIstBktRgOUiSGjq5t9LRSDINfPUo//xk4BtDjDMs5hqMuQZjrsF0NRcsLts/raqJuYPHTTksRpKp+Xblapu5BmOuwZhrMF3NBUuTzdVKkqQGy0GS1GA59GxqO8AhmGsw5hqMuQbT1VywBNnc5iBJanDJQZLUYDlIkhoshzmSvDNJJTm57SwASX41yd1J7kxyU5JT2s4EkGRjkgf62T6RZGXbmQCS/FyS+5I8maT13Q67eC30JNck2Zvk3razzJbk9CS3JLm////wHW1nAkjylCRfSHJXP9d72840W5JlSbYn+cww52s5zJLkdOAngK+1nWWWjVV1dlWdA3wG6Mq1IW8Gzqqqs+mdXn1Dy3lm3Av8DHBr20E6fC30a4EL2g4xj8eBd1bVmcC5wFs68nx9C3h5Vb0AOAe4IMm5LWea7R3AjmHP1HI42AeBy4HObKWvqn+cdfOpdCRbVd1UVY/3b/4tvQsyta6qdlTVzrZz9HXyWuhVdSvwcNs55qqqh6rqjv7vj9L7wGtcHnjUquf/9G8u7//rxPswyWnATwNXDXvelkNfknXA7qq6q+0scyV5X5IHgX9Ld5YcZnsT8Nm2Q3TQgq6FrqYkq4A1wO3tJunpr7q5E9gL3FxVncgFfIjeF9onhz3jzl7PYSkk+QvgufPcdQXwbnqrlEbucLmq6pNVdQVwRZINwFuBK7uQqz/NFfRWB1w/ikwLzaVjV5KnAR8H/uOcJefWVNUTwDn9bWufSHJWVbW6zSbJhcDeqtqW5Lxhz3+syqGqXjHfeJIfBs4A7koCvVUkdyT50ar6elu55nE9vQsgjaQcjpQryRuBC4Hza4QHzAzwfLXNa6EPKMlyesVwfVVtbjvPXFW1L8kt9LbZtL1B/8XAq5L8FPAU4BlJrquq1w1j5q5WAqrqnqp6dlWtqqpV9Bb/XziKYjiSJM+bdXMd8EBbWWZLcgG9xdlXVdU3287TUV8EnpfkjCQnAq8BPtVyps5K75vZ1cCOqvqttvPMSDIxszdekhXAj9OB92FVbaiq0/qfWa8B/nJYxQCWw7Hg/UnuTXI3vdVendi9D/gI8HTg5v5utr/fdiCAJK9Osgt4EfCnSba2laW/wX7mWug7gBu7cC30JDcAtwGrk+xKcmnbmfpeDLweeHn/NXVn/1tx274PuKX/HvwivW0OQ91ttIs8fYYkqcElB0lSg+UgSWqwHCRJDZaDJKnBcpAkNVgOkqQGy0EakSSXJvmDJLcn+Wb/1PC/1nYuaT5jdfoMqWW/CTwT+N/AHuAH2o0jHZpLDtLovAZYVVXPAlxiUKdZDtJRSrKlv2ro7fPc96v9+66eGauqP6+qr442pXR0LAfp6L2J3lUDfyPJmpnBJOfTOwX8/cDbWsomLYrlIB2lqnoYuARYBvxJkqcleQ5wHb1LS17sGWt1rLIcpEWoqr8BfgV4HvAHwEfpXYjo7V04A6t0tNxbSVq8XwdeBry2f/uGqhr6NX2lUXLJQVqk/lXwZl+17ENtZZGGxXKQFql/tb4P0Dt+4UngqiRPaTeVtDiWg7QISb4b+BPgqcC/Af4L8MO49KBjnOUgLc4HgDXAb1TVzcCVwP8EfiHJz7WaTFoELxMqHaUkr6a3reF24CX9a0aT5HTgTno7fKypqi/3x/8d8JL+n/8zetdMvhvY3h97oKreP7r/AunQLAfpKCT5J/QK4LuAc6rqK3PuXwdsoXdB+pdU1WNJrgXecJjZfr6qzluSwNKALAdJUoPbHCRJDZaDJKnBcpAkNVgOkqQGy0GS1GA5SJIaLAdJUoPlIElqsBwkSQ3/H1Byr2zszZFLAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iD1yFTPg4gHY"
      },
      "source": [
        "Similarly with 2 dimensional data containing $ x_{1} $ and $ x_{2} $ dimension new dimensions like $ x_{1}^{2} $, $ x_{2}^{2} $, $ x_{1} x_{2} $, $ x_{1}^{3} $ e.t.c can be created and data can be transformed to higher dimension to separate the classes. \n",
        "\n",
        "We have some functions which can help to transform the data to higher dimesions. These functions are known as kernels. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCDC7GfLERAf"
      },
      "source": [
        "##  Some popular Kernels in SVM\n",
        "<ul>\n",
        "<li><b>Linear</b> </li>\n",
        "<li>Polynomial </li>\n",
        "<li>Gaussian </li>\n",
        "<li>Radial Basis Function (RBF)</li>\n",
        "<li>Hyperbolic </li>\n",
        "<li>Sigmoid</li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlYjv4z1RMNn"
      },
      "source": [
        "## Implementation\n",
        "Assignment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TN9mozN88Ey"
      },
      "source": [
        "# QnA\n",
        "<ol>\n",
        "<li> Generic question for any algorithm: ADA? (Advantages, Disadvantages and Assumptions)</li>\n",
        "<b>Advantages of SVM</b> <br>\n",
        "<ul><li>Turnkey algorithm, very few parameters to optimize.</li>\n",
        "<li>Optimization is in convex space so a global minimum is reached unlike neural network it doesn't suffer with problem of stucking at local minima.</li>\n",
        "<li>Memory efficient</li>\n",
        "<li>Linear SVM is more effective than other algorithm if the number of features are highe (>1000)</li>\n",
        "</ul>\n",
        "<b>Disadvantages of SVM</b> <br>\n",
        "<ul>\n",
        "<li>Feature scaling</li>\n",
        "<li>Tends to get slower as number of examples increases</li>\n",
        "<li>Hard margin leads to overfitting</li>\n",
        "</ul>\n",
        "<b>Assumpitons</b> <br>\n",
        "<ul><li> None </li></ul>\n",
        "<li>Explain hard and soft margin in context with SVM.</li>\n",
        "<ul><li> <b>Hard Margin</b> Does not allow any error</li>\n",
        "<li> <b>Soft Margin</b> Allow error, it reduces the chance of overfitting</li>\n",
        "</ul>\n",
        "<li>Why does SVM gets slower when number of examples increases?</li>\n",
        "<ul><li> The computaion cost depends upon selection of pair of vecors ($ nC_{2} $).  </li></ul>\n",
        "<li>What are the hyperparameters associated with SVM?</li>\n",
        "<ul><li> Kernel </li>\n",
        "<li> C: Number of permitted errors. Large C gives narrow margin and vice versa. </li></ul>\n",
        "<li>Why the SVM algorithm is known to be memory efficient? </li>\n",
        "<ul><li> Not all the data points are required to make the decision, once the support vectors are decided only the support vectors and equation of the hyperplane is required to make the decision. </li></ul>\n",
        "<li>State the statement is True or False: 'SVM decision boundary is perpendicular bisector to the line joining the closest point of convex hull of the two classes'.  </li>\n",
        "<ul><li> True statement. Geometrical explanation: make convex hull of each of the class, try to join the convex hulls using the closest point and the classification boundary will be the perpendicular bisector.</li></ul>\n",
        "<li>Give a typical example where SVM will be used over RandomForest.</li>\n",
        "<ul><li> Text classification: SVM is an algorithm of choice for higher dimensional space. Number of features are large. </li></ul>\n",
        "<li>What is regularization? How is a SVM algorithm regularized? Is it L1 or L2 regularization in nature?</li>\n",
        "<ul><li> 'C parameter' is actually the <b>regularization parameter </b>. The C parameter is multiplied by sum of errors thus the regularization in general is L1 in nature. But if cost function is modified in such a way that cost of SVM is C multiplied by sum of squares of the erros the regularization becomes L2 in nature.   </li>\n",
        "$$ Loss (L1 \\ regularized) = \\frac{1}{2}|w|^{2} + C \\sum |\\zeta|$$\n",
        "$$ Loss (L2 \\ regularized) = \\frac{1}{2}|w|^{2} + C \\sum \\zeta^{2}$$\n",
        "</ul>\n",
        "\n",
        "</ol>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fYvN0eH60RG"
      },
      "source": [
        "# Recommended Readings\n",
        "<ul>\n",
        "<li>Other forms of derivation</li>\n",
        "<li>Mercer's Theorem</li>\n",
        "\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3a7_5lBBa79"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}